# Start The Servers

In one window build and start the proxy

`mvn clean install $skip tomee:run`

In another windown in the same directory, start the target service

`./runinstance.sh 7000`

# GET 3.5GB of data

----
mingus:~/work/tomitribe/proxy-large-files 01:56:05
$ ./try.sh proxy_get
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying ::1...
* TCP_NODELAY set
* Connected to localhost (::1) port 8080 (#0)
> GET /tomee-grinder-starter-1.0-SNAPSHOT/proxy/tomee-grinder-starter-1.0-SNAPSHOT/color/send/3567mb HTTP/1.1
> Host: localhost:8080
> User-Agent: curl/7.54.0
> Accept: */*
>
< HTTP/1.1 200 OK
< Date: Sun, 12 Nov 2017 14:06:33 GMT
< Transfer-Encoding: chunked
< Server: Apache TomEE
< Content-Type: application/octet-stream
< Transfer-Encoding: chunked
<
{ [8826 bytes data]
100 3567M    0 3567M    0     0   229M      0 --:--:--  0:00:15 --:--:--  245M
* Connection #0 to host localhost left intact
-rw-r--r--  1 dblevins  wheel   3.5G Nov 12 14:06 /tmp/foo.txt
----

# POST and GET 1.1GB

AsyncHttpClient seems to have a 2GB post limit of some kind

----
mingus:~/work/tomitribe/proxy-large-files 02:10:07
$ ./try.sh proxy_echo
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying ::1...
* TCP_NODELAY set
* Connected to localhost (::1) port 8080 (#0)
> POST /tomee-grinder-starter-1.0-SNAPSHOT/proxy/tomee-grinder-starter-1.0-SNAPSHOT/color/echo HTTP/1.1
> Host: localhost:8080
> User-Agent: curl/7.54.0
> Accept: */*
> Content-Length: 1234567890
> Content-Type: application/x-www-form-urlencoded
> Expect: 100-continue
>
< HTTP/1.1 100 Continue
} [16384 bytes data]
 89 1177M    0     0   89 1050M      0   561M  0:00:02  0:00:01  0:00:01  561M* We are completely uploaded and fine
< HTTP/1.1 200 OK
< Date: Sun, 12 Nov 2017 14:10:16 GMT
< Transfer-Encoding: chunked
< Server: Apache TomEE
< Content-Type: application/octet-stream
< Transfer-Encoding: chunked
<
{ [8826 bytes data]
100 2354M    0 1177M  100 1177M   117M   117M  0:00:10  0:00:10 --:--:--     0
* Connection #0 to host localhost left intact
-rw-r--r--  1 dblevins  wheel   1.1G Nov 12 14:10 /tmp/foo.txt
----

# GET 500MB over 2.5 minutes

This allows us to challenge the RequestTimeout.

----
mingus:~/work/tomitribe/proxy-large-files 05:43:30
$ ./try.sh proxy_slow 500mb 1ms
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying ::1...
* TCP_NODELAY set
* Connected to localhost (::1) port 8080 (#0)
> GET /tomee-grinder-starter-1.0-SNAPSHOT/proxy/tomee-grinder-starter-1.0-SNAPSHOT/color/slow/500mb/1ms HTTP/1.1
> Host: localhost:8080
> User-Agent: curl/7.54.0
> Accept: */*
>
< HTTP/1.1 200 OK
< Date: Sun, 12 Nov 2017 17:43:34 GMT
< Transfer-Encoding: chunked
< Server: Apache TomEE
< Content-Type: application/octet-stream
< Transfer-Encoding: chunked
<
{ [8826 bytes data]
100  500M    0  500M    0     0  3100k      0 --:--:--  0:02:45 --:--:-- 3079k
* Connection #0 to host localhost left intact
-rw-r--r--  1 dblevins  wheel   500M Nov 12 17:46 /tmp/foo.txt
----

Increase the `1ms` to `2ms` or `10ms` to make the response last longer

`./try.sh proxy_slow 100mb 1s`